<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/github-dark.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
  <link rel="stylesheet" href="style.css">
  <title>PostgreSQLの実行計画を読み解く</title>
</head>
<body class="markdown-body">

<header class="header">
  <h2 class="site-title">DB技術記事</h2>
  <button class="menu-btn" id="menuBtn">☰</button>
</header>

<h1>PostgreSQLの実行計画を読み解く</h1>

<h2>1. はじめに</h2>
<p>
本記事では、PostgreSQL 17 環境において EXPLAIN ANALYZE を用い、
クエリ実行計画と実行性能の関係を検証します。
</p>
<p>
対象読者は、SQLの基本文法（SELECT / JOIN / GROUP BY）を理解しており、
「同じ結果を返すSQLでも、なぜ速度差が出るのか」を説明できるようになりたい方です。
</p>
<p>
記事のゴールは、単に速いSQLを書くことではありません。<span class="highlight-strong">計画を読んで改善方針を説明できる</span>状態を目指します。
そのために、実行計画の読み方、統計情報の見方、インデックスの効き方、誤差が生じる条件を段階的に確認していきます。
</p>

<div class="column">
  <div class="column-title">この記事で身につくこと</div>
  <ul class="column-note">
    <li>Scan種別（Seq Scan / Index Scan / Bitmap Heap Scan）の違いを説明できます。</li>
    <li>推定行数（rows）と実測行数（actual rows）の差から、計画の妥当性を判断できます。</li>
    <li>改善手段（インデックス・SQL書き換え・統計更新）を、根拠つきで選べます。</li>
  </ul>
</div>

<div class="column">
  <div class="column-title">ウォームアップ演習：実行計画を読むとき最初に見る項目は何ですか？</div>
  <p class="column-note">
    最初は Node Type、rows（推定）、actual rows（実測）、loops を見るのがおすすめです。
    この4点で「何を、どれくらい、何回処理したか」を把握しやすくなります。
  </p>
</div>

<h2>2. 実験環境</h2>
<ul>
  <li>PostgreSQL 17</li>
  <li>Docker（演習コンテナ）</li>
  <li>OS: Windows / macOS / Linux いずれでも可</li>
  <li>クライアント: <code>psql</code></li>
</ul>

<h3>2.1 検証用スキーマの作成</h3>
<p>
以下のテーブルを作成し、注文データ（orders）と顧客データ（customers）を使って計画を比較します。
</p>
<pre><code class="language-sql">
DROP TABLE IF EXISTS orders;
DROP TABLE IF EXISTS customers;

CREATE TABLE customers (
  customer_id BIGINT PRIMARY KEY,
  prefecture  TEXT NOT NULL,
  segment     TEXT NOT NULL,
  created_at  TIMESTAMP NOT NULL DEFAULT now()
);

CREATE TABLE orders (
  order_id      BIGSERIAL PRIMARY KEY,
  customer_id   BIGINT NOT NULL,
  order_date    DATE NOT NULL,
  status        TEXT NOT NULL,
  amount        NUMERIC(12,2) NOT NULL,
  shipping_pref TEXT NOT NULL,
  created_at    TIMESTAMP NOT NULL DEFAULT now()
);
</code></pre>

<h3>2.2 サンプルデータ投入</h3>
<p>
行数が少ないと計画差が出にくいため、customers 10万件、orders 100万件を投入します。
</p>
<p><span class="critical-text">※ この処理はPCスペックにより数秒〜数十秒ほど時間がかかる場合があります。実行中に一時的に固まったように見えても、そのまま待ってください。</span></p>
<pre><code class="language-sql">
INSERT INTO customers (customer_id, prefecture, segment, created_at)
SELECT
  g,
  (ARRAY['tokyo','osaka','kanagawa','aichi','fukuoka'])[1 + (random()*4)::int],
  (ARRAY['retail','enterprise','education'])[1 + (random()*2)::int],
  now() - ((random()*3650)::int || ' days')::interval
FROM generate_series(1, 100000) AS g;

INSERT INTO orders (customer_id, order_date, status, amount, shipping_pref, created_at)
SELECT
  1 + (random()*99999)::int,
  date '2022-01-01' + ((random()*1400)::int),
  (ARRAY['new','paid','shipped','canceled'])[1 + (random()*3)::int],
  round((500 + random()*19500)::numeric, 2),
  (ARRAY['tokyo','osaka','kanagawa','aichi','fukuoka'])[1 + (random()*4)::int],
  now() - ((random()*1000)::int || ' hours')::interval
FROM generate_series(1, 1000000);

ANALYZE customers;
ANALYZE orders;
</code></pre>

<div class="column">
  <div class="column-title">演習：データ件数を半分にすると計画はどう変わりますか？</div>
  <p class="column-note">
    100万件と50万件で同じSQLを比較してみてください。件数が減ると Seq Scan の優位性が変わる場面があります。
  </p>
</div>

<h3>2.3 測定時の注意</h3>
<ul>
  <li>初回実行の結果を確認し、ディスクI/O影響（キャッシュ未温）を切り分けます。</li>
  <li>同じSQLを複数回実行し、中央値を比較します。</li>
  <li>EXPLAIN だけで終えず、EXPLAIN ANALYZE で実測を確認します。</li>
</ul>

<div class="column">
  <div class="column-title">補足：本番でEXPLAIN ANALYZEを使うとき</div>
  <p class="column-note">
    EXPLAIN ANALYZE は実際にクエリを実行します。更新系SQLでは影響が出るため、<span class="critical-text">検証環境で再現して確認することは必須</span>です。
  </p>
</div>

<div class="column">
  <div class="column-title">よくある疑問：インデックスを作れば必ず速くなるか</div>
  <p class="column-note">
    必ずしも速くなりません。条件の選択性が低い場合や、取得列が多い場合は <code>Seq Scan</code> が有利なことがあります。
    追加前後で <code>EXPLAIN (ANALYZE, BUFFERS)</code> を比較して判断することが<span class="critical-text">必須</span>です。
  </p>
</div>

<h3>定着確認（第2章）</h3>
<ul>
  <li>性能確認では <span class="masked">EXPLAIN ANALYZE</span> で実測を取るべきである。</li>
  <li>更新系SQLの検証は <span class="masked">本番ではなく検証環境</span> で行うべきである。</li>
  <li>比較時は <span class="masked">同一SQLを複数回実行</span> し、中央値で判断すべきである。</li>
</ul>

<h2>3. EXPLAIN / ANALYZE の基本</h2>
<p>
EXPLAIN は「実行前の見込み計画」、EXPLAIN ANALYZE は「実際に実行した結果付き計画」です。
チューニングでは、まず見込みと実測の差を確認します。
</p>

<h3>3.1 まず読むべき項目</h3>
<ul>
  <li><span class="highlight">Node Type</span>：Seq Scan / Index Scan / Hash Join など</li>
  <li><span class="highlight">cost</span>：プランナが比較に使う相対値</li>
  <li><span class="highlight">rows</span>：推定行数</li>
  <li><span class="highlight">actual rows</span>：実際の処理行数</li>
  <li><span class="highlight">loops</span>：ノードが繰り返された回数</li>
</ul>
<p>
ここで最も誤解しやすい点は、<span class="highlight">actual rows は1ループあたりの平均行数</span>として表示される場合があることです。
そのため、実際の総処理行数は <span class="highlight">actual rows × loops</span> で読み取るのが基本です。
たとえば <code>actual rows=120</code>、<code>loops=50</code> なら、合計では約6,000行を処理したと解釈できます。
</p>

<h3>3.2 単純フィルタ</h3>
<p>
まず説明を先に確認します。プランナは「該当行が全体の何割か」を統計情報から推定し、
ランダムI/O中心になるIndexアクセスと、順次読み取り中心になるSeq Scanを比較します。
</p>
<pre><code class="language-sql">
EXPLAIN (ANALYZE, BUFFERS)
SELECT *
FROM orders
WHERE status = 'paid';
</code></pre>
<p>
status列にインデックスがない場合、通常は Seq Scan が選ばれます。全件を確認して条件を満たす行だけ返すため、
行数が増えるほど時間は増加しやすくなります。
</p>
<p>
具体例として、100万件中25万件（25%）が <code>status='paid'</code> に該当する分布では、
インデックスがあっても「大量ヒット + テーブル参照」のコストが高くなり、Seq Scanが有利になりやすいです。
一方で1万件（1%）程度しかヒットしない条件なら、Index ScanやBitmap Heap Scanが選ばれやすくなります。
</p>

<div class="column">
  <div class="column-title">演習：rows と actual rows の差はどれくらいなら要注意ですか？</div>
  <p class="column-note">
    一律の閾値はありませんが、10倍以上の差が続く場合は統計不足や相関の見落としを疑うとよいです。
  </p>
</div>

<h3>3.3 典型ノードの意味</h3>
<ul>
  <li>Seq Scan：テーブル全体走査。広い条件や低選択性条件で選ばれやすい</li>
  <li>Index Scan：インデックスを辿って該当行へアクセス</li>
  <li>Bitmap Heap Scan：多数ヒット時に、先にビットマップで集めてから読み込む</li>
  <li>Nested Loop：外側行ごとに内側を探す。小さい集合同士で強い</li>
  <li>Hash Join：片側をハッシュ化して突き合わせる。中〜大規模で有効</li>
</ul>

<h3>3.4 costの解釈</h3>
<p>
cost は時間（ms）そのものではなく、プランナ内部の評価値です。したがって cost が半分でも、実行時間が半分になるとは限りません。
ただし同一環境・同一時点で候補プランを比べる指標としては有効です。
</p>
<p>
cost には主に <code>seq_page_cost</code> と <code>random_page_cost</code>、CPU演算の重みが反映されます。
つまり、同じデータ件数でも「連続読み取り中心か」「ランダム読み取り中心か」で評価が大きく変わります。
実行時間との差分は、キャッシュ状態・同時実行・ストレージ性能の影響で発生するため、
最終判断は必ず <code>EXPLAIN (ANALYZE, BUFFERS)</code> の実測で行う必要があります。
</p>

<h3>3.5 標準分析テンプレート（まずこれを実行）</h3>
<p>
クエリが遅いと感じたら、最初に次のテンプレートを実行してください。<span class="highlight">実行計画・統計情報・インデックス定義</span>を同時に確認できます。
</p>
<pre><code class="language-sql">
-- 1) 対象SQLの実測計画を取得
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT o.order_id, o.customer_id, o.amount
FROM orders o
WHERE o.status = 'paid'
  AND o.order_date &gt;= current_date - 30;
</code></pre>
<p>
最初に <span class="highlight">Node Type</span>、<span class="highlight">actual rows</span>、<span class="highlight">loops</span> を確認してください。
この段階で「どの処理が何回実行されているか」を把握できます。
</p>
<pre><code class="language-text">
Limit  (actual time=12.4..12.9 rows=200 loops=1)
  -&gt;  Index Scan using idx_orders_status_date on orders o
      (actual time=12.3..12.8 rows=200 loops=1)
</code></pre>
<p>
上のように <span class="highlight">Index Scan</span> へ切り替わっているか、
<span class="highlight">actual time</span> が改善しているかを見てください。
</p>

<pre><code class="language-sql">
-- 2) 統計情報（偏り・distinct）を確認
SELECT schemaname, tablename, attname, n_distinct, most_common_vals, most_common_freqs
FROM pg_stats
WHERE tablename = 'orders'
  AND attname IN ('status', 'order_date', 'shipping_pref');
</code></pre>
<p>
ここでは <span class="highlight">most_common_vals</span> と <span class="highlight">most_common_freqs</span> を見て、
対象条件の偏りを確認してください。偏りが大きい場合は、計画が急に切り替わる原因になります。
</p>

<pre><code class="language-sql">
-- 3) インデックス定義を確認
SELECT indexname, indexdef
FROM pg_indexes
WHERE tablename = 'orders'
ORDER BY indexname;
</code></pre>
<p>
対象SQLの <code>WHERE</code> / <code>ORDER BY</code> とインデックス列順が一致しているかを確認してください。
一致していない場合、インデックスが存在しても使われないことがあります。
</p>

<pre><code class="language-sql">
-- 4) テーブル統計の更新時刻・件数感を確認
SELECT relname, n_live_tup, n_dead_tup, last_analyze, last_autoanalyze
FROM pg_stat_user_tables
WHERE relname IN ('orders', 'customers');
</code></pre>
<p>
<span class="highlight">last_analyze</span> が古い場合、rows推定が外れて不利な計画につながります。
大量更新後は統計更新の実施有無を必ず確認してください。
</p>

<div class="column">
  <div class="column-title">テンプレート運用のコツ</div>
  <p class="column-note">
    取得した結果は、<span class="highlight">rows推定誤差</span>、<span class="highlight">buffers read/hit</span>、<span class="highlight">利用インデックス</span>の3軸で並べて比較してください。
  </p>
</div>

<h3>3.6 BUFFERSによるI/Oとキャッシュの切り分け</h3>
<p>
<code>BUFFERS</code> は、遅延の主因がディスクI/Oか、CPU処理かを切り分けるための重要情報です。
<span class="highlight">shared hit</span> が多い場合はキャッシュ命中中心、
<span class="highlight">shared read</span> が多い場合は実ディスク読み込み中心と判断できます。
</p>
<pre><code class="language-text">
Seq Scan on orders  (actual time=0.120..820.331 rows=250000 loops=1)
Buffers: shared hit=1200 read=18450
</code></pre>
<p>
この例では <span class="highlight">read が多い</span>ため、I/O待ちが主要因である可能性が高いです。
同じSQLを再実行して <span class="highlight">hit が増え read が減る</span>なら、キャッシュ効果が確認できます。
</p>

<div class="column">
  <div class="column-title">演習：同じSQLを3回実行したとき、どの値を比較しますか？</div>
  <p class="column-note">
    実行時間だけでなく、buffers の read/hit、actual rows、loops も合わせて比較してください。
    ばらつきが小さい条件で比較することが重要です。
  </p>
</div>

<h3>定着確認（第3章）</h3>
<ul>
  <li>実行計画の初見では <span class="masked">Node Type / rows / actual rows / loops</span> を優先確認すべきである。</li>
  <li><code>cost</code> は <span class="masked">相対評価値</span> であり、実時間と一致しない前提で扱うべきである。</li>
  <li>原因切り分けでは <span class="masked">buffers read/hit</span> を実行時間と併せて確認すべきである。</li>
</ul>

<h2>4. データ量と実行計画の変化</h2>
<p>
同一SQLでも、データ量が増えるとプランナが採用する計画は変化します。ここでは件数を増やしながら比較します。
</p>

<h3>4.1 小規模データ・1万件</h3>
<pre><code class="language-sql">
EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id, amount
FROM orders
WHERE order_date &gt;= date '2025-01-01';
</code></pre>
<p>
対象が多い場合、インデックスがあっても Seq Scan が勝つことがあります。ランダムアクセスのオーバーヘッドより、
連続読み込みの方が速くなるためです。
</p>

<h3>4.2 中規模データ・100万件</h3>
<p>
order_date の選択性が高い条件（例えば直近7日）に変更すると、Index Scan または Bitmap Heap Scan に切り替わりやすくなります。
</p>
<pre><code class="language-sql">
EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id, amount
FROM orders
WHERE order_date &gt;= current_date - 7;
</code></pre>
<pre><code class="language-text">
Bitmap Heap Scan on orders  (actual time=8.221..35.744 rows=5120 loops=1)
  Recheck Cond: (order_date &gt;= (CURRENT_DATE - 7))
  Buffers: shared hit=980 read=120
</code></pre>
<p>
注目点は <span class="highlight">Node Type</span> と <span class="highlight">rows</span>、
そして <span class="highlight">Buffers</span> の read/hit 比率です。これらを前回結果と比較してください。
</p>
<p>
例えば、100万件中「直近7日」が約5,000件（0.5%）なら、該当ページだけを効率よく拾えるIndex系ノードが有利です。
逆に20万件以上が該当する条件では、ページを広範囲に読む必要があるためSeq Scanへ戻る可能性が高くなります。
この切替点は統計情報とテーブル分布に依存するため、実データでの観測が不可欠です。
</p>

<h3>4.3 大規模データでの集計</h3>
<p>
集計は「入力をどう並べるか」「中間結果をどこに保持するか」で計画が変わります。
都道府県のようにグループ数が少ない列では、HashAggregateでメモリ内集計できると速くなる傾向があります。
一方、入力が既に整列済み、またはSortコストが低い場合はGroupAggregateが選ばれることがあります。
</p>
<pre><code class="language-sql">
EXPLAIN (ANALYZE, BUFFERS)
SELECT shipping_pref, COUNT(*)
FROM orders
GROUP BY shipping_pref;
</code></pre>
<p>
GroupAggregate と HashAggregate のどちらが出るかは、並び順やメモリ設定、推定行数に依存します。
</p>
<p>
具体例として、<code>shipping_pref</code> が5種類に偏る分布なら、100万件入力でもハッシュ表は小さく保てます。
ただし <code>work_mem</code> が不足するとハッシュがディスク退避し、想定より遅くなることがあります。
そのため、Node名だけでなく <code>BUFFERS</code> と実行時間を併せて比較することが重要です。
</p>

<div class="column">
  <div class="column-title">観察ポイント</div>
  <p class="column-note">
    実行時間だけで判断しないことが重要です。Node構成、rows推定誤差、buffersのread/hitを同時に見て「なぜ遅いか」を説明してください。
  </p>
</div>

<div class="column">
  <div class="column-title">演習：件数が増えると、どのタイミングでNode Typeが切り替わりますか？</div>
  <p class="column-note">
    10万件・50万件・100万件の順に同じSQLを実行し、
    <span class="highlight">どの件数で Seq Scan から Index系ノードへ切り替わったか</span>を確認してください。
    あわせて rows と actual rows の差、実行時間、BUFFERS(read/hit) を表にして比較すると、
    「なぜその計画が選ばれたか」を説明しやすくなります。
  </p>
</div>

<h3>定着確認（第4章）</h3>
<ul>
  <li>同一SQLでもデータ量で <span class="masked">Node Type が変わる</span> 可能性がある点を前提に評価すべきである。</li>
  <li>計画比較は <span class="masked">実行時間だけで判断しない</span> のが原則である。</li>
  <li>比較時は <span class="masked">rows誤差とBUFFERS(read/hit)</span> を同時に見るべきである。</li>
</ul>

<h2>5. インデックスの影響</h2>
<p>
インデックスは万能ではありません。たとえば、社員名簿で「全社員を表示する」検索に索引を使っても速くならないのと同じで、
ヒット件数が多すぎる条件ではテーブル全体走査の方が有利になる場合があります。
</p>
<p>
そのため、列の選択性、WHERE句の書き方、戻り列、並び替え条件まで含めて設計する必要があります。
「どのクエリを何回実行するか」を前提に、効果と更新コストの両方で判断してください。
</p>

<h3>5.1 単一列インデックス</h3>
<pre><code class="language-sql">
CREATE INDEX idx_orders_status ON orders(status);
ANALYZE orders;

EXPLAIN (ANALYZE, BUFFERS)
SELECT *
FROM orders
WHERE status = 'canceled';
</code></pre>
<pre><code class="language-text">
Index Scan using idx_orders_status on orders  (actual time=0.201..42.105 rows=20034 loops=1)
  Index Cond: (status = 'canceled'::text)
</code></pre>
<p>
このサンプルでは <span class="highlight">Index Scan</span> への切り替わりが確認できます。
比較時は <span class="highlight">actual time</span> と <span class="highlight">rows</span> の両方を見て、
単にNode名だけでなく実効性能で判断してください。
</p>
<p>
status='canceled' が低頻度なら Index Scan が効きやすくなります。逆に頻度が高すぎると Seq Scan が選ばれます。
</p>
<p>
例えば100万件中 <code>canceled</code> が2万件（2%）なら、インデックス経由で必要行だけ辿る方が有利になりやすいです。
一方で40万件（40%）が該当する分布では、インデックス経由のランダムアクセスが増え、Seq Scanの方が安く評価されることがあります。
この違いが「インデックスは作れば必ず速いわけではない」理由です。
</p>

<h3>5.2 複合インデックス</h3>
<pre><code class="language-sql">
CREATE INDEX idx_orders_status_date ON orders(status, order_date);
ANALYZE orders;

EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id, amount
FROM orders
WHERE status = 'paid'
  AND order_date &gt;= date '2025-01-01';
</code></pre>
<p>
複合インデックスは列順が重要です。先頭列の条件がないと効きにくくなります。
</p>

<h3>5.3 カバリングインデックス・INCLUDE</h3>
<pre><code class="language-sql">
CREATE INDEX idx_orders_paid_date_include
ON orders(order_date)
INCLUDE (amount, status);
</code></pre>
<p>
必要列がインデックス内で完結すると Index Only Scan が選択され、テーブル参照を減らせる場合があります。
</p>

<h3>5.4 不要インデックスの副作用</h3>
<ul>
  <li>INSERT / UPDATE / DELETE が遅くなる</li>
  <li>VACUUM やメンテナンスの負荷が上がる</li>
  <li>ストレージを圧迫する</li>
</ul>

<details>
  <summary>補足：部分インデックスの活用</summary>
  <pre><code class="language-sql">
CREATE INDEX idx_orders_canceled_partial
ON orders(order_date)
WHERE status = 'canceled';
  </code></pre>
  <p>
  条件が偏っている場合、部分インデックスはサイズ削減と検索高速化を同時に狙えます。
  </p>
</details>

<div class="column">
  <div class="column-title">演習：どの条件なら部分インデックスを採用しますか？</div>
  <p class="column-note">
    低頻度で、かつ業務上よく検索する条件に向いています。運用前に更新コストも含めて評価してください。
  </p>
</div>

<div class="column">
  <div class="column-title">演習：複合インデックスの列順を逆にしたときの差を観測してください</div>
  <p class="column-note">
    実行時間だけでなく、Node Type・loops・buffers の差を比較して、どちらが目的クエリに適しているか説明してみてください。
  </p>
</div>

<h3>定着確認（第5章）</h3>
<ul>
  <li>インデックス設計では <span class="masked">選択性と列順</span> を先に確認すべきである。</li>
  <li>複合インデックスは <span class="masked">先頭列条件</span> がないと効きにくい点を理解すべきである。</li>
  <li>索引追加は検索性能だけでなく <span class="masked">更新コスト</span> も評価すべきである。</li>
</ul>

<h2>6. 統計情報と推定誤差</h2>
<p>
プランナは統計情報を使って rows を推定します。推定が外れると、計画選択も外れます。
</p>

<h3>6.1 どこを見るか</h3>
<ul>
  <li>EXPLAIN の rows と actual rows の比率</li>
  <li><code>pg_stats</code> の n_distinct / most_common_vals</li>
  <li>ANALYZE 実行タイミング</li>
</ul>

<h3>6.2 推定誤差の再現</h3>
<p>
特定ステータスへデータを極端に偏らせると、古い統計では誤推定が発生しやすくなります。
</p>
<pre><code class="language-sql">
UPDATE orders
SET status = 'paid'
WHERE order_id % 10 &lt; 8;

-- あえてANALYZEせずに確認
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE status = 'paid';
</code></pre>
<p>
この操作では、理論上は100万件のうち約80万件が <code>paid</code> になります。
それでも統計が古いままだと、プランナは「まだ25%程度」と誤認し、
不利なアクセス経路を選ぶ場合があります。<code>rows</code> と <code>actual rows</code> の乖離を観測すると、
統計起因の問題を定量的に説明できます。
</p>

<h3>6.3 改善手順</h3>
<pre><code class="language-sql">
ANALYZE orders;

EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE status = 'paid';
</code></pre>
<p>
ANALYZE 後に rows 推定が actual rows に近づけば、統計不足が原因だった可能性が高いです。
</p>

<h3>6.4 相関が強い列への対策</h3>
<p>
列同士の相関が強い場合、単純統計では誤差が残ります。必要に応じて extended statistics を使います。
</p>
<pre><code class="language-sql">
CREATE STATISTICS st_orders_status_pref (dependencies)
ON status, shipping_pref
FROM orders;

ANALYZE orders;
</code></pre>

<div class="column">
  <div class="column-title">実務メモ</div>
  <p class="column-note">
    大量更新直後は統計が古くなりやすいです。夜間バッチ後の遅延は、インデックス不足より統計更新漏れが原因のことも多いです。
  </p>
</div>

<div class="column">
  <div class="column-title">演習：ANALYZE前後でどの列の統計を確認しますか？</div>
  <p class="column-note">
    WHERE句やJOIN条件で使う列を優先して確認します。<code>pg_stats</code> の most_common_vals や n_distinct が参考になります。
  </p>
</div>

<div class="column">
  <div class="column-title">演習：extended statistics が有効なケースを挙げてください</div>
  <p class="column-note">
    status と shipping_pref のように、列同士の依存関係が強いケースで効果を発揮しやすいです。
  </p>
</div>

<h3>定着確認（第6章）</h3>
<ul>
  <li>rows と actual rows の乖離が大きい場合は <span class="masked">統計情報の古さ</span> を疑うべきである。</li>
  <li>偏った更新後は <span class="masked">ANALYZE</span> の実施が必須である。</li>
  <li>列相関が強い場合は <span class="masked">extended statistics</span> を検討すべきである。</li>
</ul>

<h2>7. 実行計画と実行時間の乖離</h2>
<p>
見た目の計画が同じでも、実行時間が異なることがあります。主因はキャッシュ、同時実行、パラメータ、I/O待ちです。
</p>

<h3>7.1 キャッシュ有無の差</h3>
<pre><code class="language-sql">
EXPLAIN (ANALYZE, BUFFERS)
SELECT SUM(amount)
FROM orders
WHERE order_date &gt;= current_date - 30;
</code></pre>
<p>
1回目は read が多く、2回目以降は hit が増えます。この差だけで体感速度は大きく変わります。
</p>

<h3>7.2 パラメータ値による差</h3>
<p>
同じSQLテンプレートでも、値の偏りにより最適計画が変わります。prepared statement 運用では、
generic plan / custom plan の挙動にも注意します。
</p>

<h3>7.3 JOINでの落とし穴</h3>
<p>
JOINでは、外側入力の行数推定が少し外れるだけで最適解が変わることがあります。
特に、Nested Loopは「外側が小さい」前提で高速化されるため、
推定が過小だと内側探索が想定回数を超え、急激に遅くなる場合があります。
</p>
<pre><code class="language-sql">
EXPLAIN (ANALYZE, BUFFERS)
SELECT c.prefecture, COUNT(*)
FROM customers c
JOIN orders o ON o.customer_id = c.customer_id
WHERE o.order_date &gt;= date '2025-01-01'
GROUP BY c.prefecture;
</code></pre>
<p>
Hash Join と Nested Loop の選択は、外側行数推定に強く依存します。rows 誤差が大きいと不利なJOIN方式を選ぶ可能性があります。
</p>
<p>
例えば、実際には20万件がJOIN対象なのに2万件と推定された場合、
Nested Loopが選ばれて内側アクセスが過剰に発生することがあります。
このようなケースでは、統計更新や条件見直しで推定精度を上げることが、
単純なインデックス追加より有効な対策になることがあります。
</p>

<h3>7.4 計画比較の型を作る</h3>
<ul>
  <li>同一SQLを3回実行し、中央値を比較します。</li>
  <li>ANALYZE前後で rows 誤差を比較します。</li>
  <li>インデックス追加前後で Node構成を比較します。</li>
  <li>BUFFERS read/hit の変化を記録し、要因を切り分けます。</li>
</ul>

<h3>7.5 インデックスがあるのに遅いケースを再現する</h3>
<p>
ここでは「あえて遅い状態」を作り、<span class="highlight">統計情報が古いと最悪の計画が選ばれる</span>ケースを再現します。
</p>
<p><span class="critical-text">※ この節の <code>UPDATE</code> は100万件規模に影響するため、PCスペックによって数秒〜数十秒かかる場合があります。処理中はそのまま待機してください。</span></p>
<div class="column">
  <div class="column-title">演習ステップ</div>
  <ul class="column-note">
    <li>ステップ1：現状を確認する（基準の実行計画と時間を記録する）。</li>
    <li>ステップ2：偏った更新を大量実行し、ANALYZEせずに計画悪化を観測する。</li>
    <li>ステップ3：ANALYZE後に再実行し、計画と実行時間の回復を比較する。</li>
  </ul>
</div>
<pre><code class="language-sql">
-- ステップ1: 基準計測
EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id, amount
FROM orders
WHERE status = 'canceled'
  AND order_date &gt;= current_date - 30
ORDER BY order_date DESC
LIMIT 200;

-- ステップ2: 分布を意図的に崩す（統計は更新しない）
UPDATE orders
SET status = 'canceled'
WHERE order_id % 10 &lt; 8;

EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id, amount
FROM orders
WHERE status = 'canceled'
  AND order_date &gt;= current_date - 30
ORDER BY order_date DESC
LIMIT 200;

-- ステップ3: 統計更新後に再比較
ANALYZE orders;

EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id, amount
FROM orders
WHERE status = 'canceled'
  AND order_date &gt;= current_date - 30
ORDER BY order_date DESC
LIMIT 200;
</code></pre>

<details>
  <summary>補足：pg_stat_statementsとの併用</summary>
  <p>
  単発のEXPLAINだけでは偏るため、継続的な遅いSQLの傾向は <code>pg_stat_statements</code> で観測すると改善優先度を決めやすくなります。
  </p>
</details>

<div class="column">
  <div class="column-title">参考質問例</div>
  <p class="column-note">
    「このSQLの実行計画で最初に確認すべき3項目（Node Type / rows / actual rows）を挙げ、
    それぞれから何を判断するかを1文ずつ説明してください。」
  </p>
</div>

<div class="column">
  <div class="column-title">演習：同じ計画なのに遅いとき、最初に何を確認しますか？</div>
  <p class="column-note">
    BUFFERSのread/hit、同時実行状況、実行タイミング（バッチ時間帯）を優先的に確認してください。
  </p>
</div>

<p>
ここまでで「計画の読み方」と「乖離の原因切り分け」を確認できました。
次はSQLドリルで、観測→仮説→再測定を通して説明力を仕上げます。
</p>

<h3>定着確認（第7章）</h3>
<ul>
  <li>同一計画でも実行時間差の主因は <span class="masked">キャッシュ/I/O/同時実行</span> である。</li>
  <li>再現実験では <span class="masked">基準計測→要因変更→再計測</span> の順序を守るべきである。</li>
  <li>継続監視には <span class="masked">pg_stat_statements</span> の併用が有効である。</li>
</ul>

<h2>8. SQLドリル</h2>
<p>
実行計画を読む練習として、各課題をステップ形式で実施します。
</p>
<p>
本章は、これまでの講義のように「正しいSQLを書く」ドリルではありません。用意されたSQLを実行し、
出力された実行計画（EXPLAINの結果）を読み解いて、<span class="highlight-strong">なぜその結果になったのかを考察する分析レポートを書く</span>練習です。
「どの指標が、どのように変化したか」を根拠つきで説明してください。
</p>

<div class="column">
  <div class="column-title">解答例の場所</div>
  <p class="column-note">
    各ドリルの解答は、それぞれの問題ブロック直下にある「<strong>解答例を見る</strong>」内にあります。
    手順を実行してから、同じドリル内の解答を開いて差分を確認してください。
  </p>
</div>

<div class="column">
  <div class="column-title">環境再構築の案内</div>
  <p class="column-note">
    演習でテーブル状態が崩れた場合は、<code>from-teacher/10/create-x_db.sql</code> を実行して初期状態へ戻してください。
    例：<code>npm run sql from-teacher/10/create-x_db.sql</code>
    <br>
    ※もし <code>orders</code> や <code>customers</code> テーブルのデータ状態をおかしくしてしまい、初期化したい場合は、<strong>2.1章および2.2章のテーブル作成・データ投入SQLを再度実行</strong>してください。
  </p>
</div>

<div class="column">
  <div class="column-title">ドリルの進め方（共通）</div>
  <ul class="column-note">
    <li>ステップ1：現状確認（クエリ遅延と実行計画を観測する）。</li>
    <li>ステップ2：仮説と対策（インデックス追加・統計更新・SQL書き換えを試す）。</li>
    <li>ステップ3：事後検証（改善後の計画と実行時間を比較する）。</li>
  </ul>
</div>

<h3>ex-01.sql：status条件の選択性差を比較し、実行計画の違いを説明してください。</h3>
<p><strong>課題</strong>：ステップ1〜3を実行し、以下の問いに答えてください。</p>
<ol>
  <li>インデックス追加後、<code>status='paid'</code> と <code>status='canceled'</code> で、それぞれどの <code>Node Type</code> が選ばれましたか。</li>
  <li>なぜ異なる <code>Node Type</code> が選ばれたと推測できますか。<span class="highlight">選択性（データ頻度）</span>という言葉を使って説明してください。</li>
  <li><code>BUFFERS</code>（read/hit）と実行時間の関係から、どちらの条件でインデックス効果が高かったかを述べてください。</li>
</ol>
<pre><code class="language-sql">
-- ステップ1: 現状確認
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE status = 'paid';

EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE status = 'canceled';

-- ステップ2: 仮説と対策（statusインデックスを追加）
CREATE INDEX IF NOT EXISTS idx_orders_status_drill ON orders(status);
ANALYZE orders;

-- ステップ3: 事後検証
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE status = 'paid';

EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE status = 'canceled';
</code></pre>
<details>
  <summary>解答例を見る</summary>
  <pre><code class="language-sql">
-- 解答例
CREATE INDEX IF NOT EXISTS idx_orders_status_drill ON orders(status);
ANALYZE orders;

EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE status = 'paid';

EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE status = 'canceled';

-- 観察ポイント:
-- paid が高頻度なら Seq Scan が選ばれやすい
-- canceled が低頻度なら Index Scan / Bitmap 系が選ばれやすい
  </code></pre>
  <p>
  解説：選択性の高低でプランナの判断は変わります。インデックス追加前後の Node Type と BUFFERS をセットで比較してください。
  </p>
  <p><strong>解答例</strong></p>
  <p>
  1. <code>paid</code> では <code>Seq Scan</code>、<code>canceled</code> では <code>Index Scan</code>（または <code>Bitmap Heap Scan</code>）が選ばれました。<br>
  2. 理由は選択性の差です。<code>paid</code> は該当件数が多く、全表走査の方が有利になりやすい一方、<code>canceled</code> は低頻度でインデックスアクセスが効きやすいためです。<br>
  3. <code>canceled</code> 側では read が抑えられ、実行時間も短縮しやすいことを確認できました。
  </p>
</details>

<h3>ex-02.sql：複合インデックスの列順差を比較し、最適な列順を説明してください。</h3>
<p><strong>課題</strong>：ステップ1〜3を実行し、以下の問いに答えてください。</p>
<ol>
  <li><code>idx_a(status, order_date)</code> と <code>idx_b(order_date, status)</code> のうち、対象SQLで実際に利用されやすかったのはどちらですか。</li>
  <li>その結果を、<span class="highlight">先頭列</span>という言葉を使って説明してください。</li>
  <li><code>Node Type</code>、実行時間、<code>BUFFERS</code> を比較し、どちらが実務上の採用候補かを述べてください。</li>
</ol>
<pre><code class="language-sql">
-- ステップ1: 現状確認
EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id
FROM orders
WHERE status = 'paid'
  AND order_date &gt;= date '2025-01-01';

-- ステップ2: 仮説と対策
CREATE INDEX IF NOT EXISTS idx_a ON orders(status, order_date);
CREATE INDEX IF NOT EXISTS idx_b ON orders(order_date, status);
ANALYZE orders;

-- ステップ3: 事後検証
EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id
FROM orders
WHERE status = 'paid'
  AND order_date &gt;= date '2025-01-01';
</code></pre>
<details>
  <summary>解答例を見る</summary>
  <pre><code class="language-sql">
-- 解答例
DROP INDEX IF EXISTS idx_a;
DROP INDEX IF EXISTS idx_b;

CREATE INDEX idx_a ON orders(status, order_date);
CREATE INDEX idx_b ON orders(order_date, status);
ANALYZE orders;

EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id
FROM orders
WHERE status = 'paid'
  AND order_date &gt;= date '2025-01-01';

-- 観察ポイント:
-- status条件が固定で存在するなら idx_a が有利になりやすい
  </code></pre>
  <p>
  解説：複合インデックスは先頭列が重要です。WHERE句で先頭列を固定できる構成ほど効きやすくなります。
  </p>
  <p><strong>解答例</strong></p>
  <p>
  1. 対象SQLでは <code>idx_a(status, order_date)</code> の方が使われやすい結果でした。<br>
  2. 理由は先頭列に <code>status</code> を置けており、WHERE句の等価条件に一致するためです。<br>
  3. 実行時間とBUFFERSでも <code>idx_a</code> 側が有利で、現行SQLにはこちらを採用すべきと判断しました。
  </p>
</details>

<h3>ex-03.sql：統計誤差を再現し、ANALYZEで推定精度を回復してください。</h3>
<p><strong>課題</strong>：ステップ1〜3を実行し、以下の問いに答えてください。</p>
<ol>
  <li><code>ANALYZE</code> 前後で <code>rows</code> と <code>actual rows</code> の差はどう変化しましたか。</li>
  <li>この変化を、<span class="highlight">統計情報の鮮度</span>という言葉を使って説明してください。</li>
  <li><code>Node Type</code> や実行時間に改善が見られたかを、数値を挙げて記述してください。</li>
</ol>
<pre><code class="language-sql">
-- ステップ1: 現状確認
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE shipping_pref = 'tokyo';

-- ステップ2: 仮説と対策（分布を偏らせた直後、統計未更新の状態を作る）
UPDATE orders
SET shipping_pref = 'tokyo'
WHERE order_id % 5 = 0;

EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE shipping_pref = 'tokyo';

ANALYZE orders;

-- ステップ3: 事後検証
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE shipping_pref = 'tokyo';
</code></pre>
<details>
  <summary>解答例を見る</summary>
  <pre><code class="language-sql">
-- 解答例
UPDATE orders
SET shipping_pref = 'tokyo'
WHERE order_id % 5 = 0;

EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE shipping_pref = 'tokyo';

ANALYZE orders;

EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE shipping_pref = 'tokyo';

-- 観察ポイント:
-- ANALYZE前後で rows と actual rows の乖離が縮まるか確認する
  </code></pre>
  <p>
  解説：本問の主眼は rows 推定誤差の観測です。ANALYZE前後で rows と actual rows の差が縮むかを確認してください。
  </p>
  <p><strong>解答例</strong></p>
  <p>
  1. <code>ANALYZE</code> 前は rows 推定と actual rows の乖離が大きく、実態と計画がずれていました。<br>
  2. <code>ANALYZE</code> 後は統計情報の鮮度が回復し、rows 推定が actual rows に近づきました。<br>
  3. その結果、Node選択と実行時間が安定し、計画の妥当性が改善しました。
  </p>
</details>

<h3>ex-04.sql：JOIN条件変更による Hash Join と Nested Loop の切替を比較してください。</h3>
<p><strong>課題</strong>：ステップ1〜3を実行し、以下の問いに答えてください。</p>
<ol>
  <li>各ステップで選ばれたJOINノード（<code>Hash Join</code> / <code>Nested Loop</code>）を整理してください。</li>
  <li>JOIN方式の変化を、<span class="highlight">入力行数（外側行数）</span>という言葉を使って説明してください。</li>
  <li><code>loops</code> と実行時間の関係から、どの条件が最も効率的だったかを述べてください。</li>
</ol>
<pre><code class="language-sql">
-- ステップ1: 現状確認
EXPLAIN (ANALYZE, BUFFERS)
SELECT c.segment, COUNT(*)
FROM customers c
JOIN orders o ON o.customer_id = c.customer_id
WHERE o.status = 'canceled'
GROUP BY c.segment;

-- ステップ2: 仮説と対策（抽出行数が少ない条件へ変更）
EXPLAIN (ANALYZE, BUFFERS)
SELECT c.segment, COUNT(*)
FROM customers c
JOIN orders o ON o.customer_id = c.customer_id
WHERE o.status = 'canceled'
  AND o.order_date &gt;= current_date - 3
GROUP BY c.segment;

-- ステップ3: 事後検証（ノード切替を比較）
EXPLAIN (ANALYZE, BUFFERS)
SELECT c.segment, COUNT(*)
FROM customers c
JOIN orders o ON o.customer_id = c.customer_id
WHERE o.status = 'paid'
GROUP BY c.segment;
</code></pre>
<details>
  <summary>解答例を見る</summary>
  <pre><code class="language-sql">
-- 解答例
EXPLAIN (ANALYZE, BUFFERS)
SELECT c.segment, COUNT(*)
FROM customers c
JOIN orders o ON o.customer_id = c.customer_id
WHERE o.status = 'canceled'
  AND o.order_date &gt;= current_date - 3
GROUP BY c.segment;

EXPLAIN (ANALYZE, BUFFERS)
SELECT c.segment, COUNT(*)
FROM customers c
JOIN orders o ON o.customer_id = c.customer_id
WHERE o.status = 'paid'
GROUP BY c.segment;

-- 観察ポイント:
-- 抽出行が少ない場合は Nested Loop が有利になる場面がある
-- 対象行が増えると Hash Join が優勢になりやすい
  </code></pre>
  <p>
  解説：JOIN方式は入力行数の見積もりに強く依存します。条件を変えて対象件数を動かし、ノード切替を確認してください。
  </p>
  <p><strong>解答例</strong></p>
  <p>
  1. 抽出件数が少ない条件では <code>Nested Loop</code>、件数が増える条件では <code>Hash Join</code> が選ばれました。<br>
  2. 理由は入力行数の差です。外側行数が小さいと逐次探索が有利ですが、行数が増えるとハッシュ結合が有利になります。<br>
  3. loops と実行時間を比較すると、対象行が少ない条件で最も効率が高いことを確認できました。
  </p>
</details>

<h3>ex-05.sql：ORDER BY最適化のための索引を追加し、Sort有無を比較してください。</h3>
<p><strong>課題</strong>：ステップ1〜3を実行し、以下の問いに答えてください。</p>
<ol>
  <li>インデックス追加前後で <code>Sort</code> ノードの有無はどう変化しましたか。</li>
  <li>その変化を、<span class="highlight">ORDER BY とインデックス列順の一致</span>という言葉を使って説明してください。</li>
  <li><code>BUFFERS</code> と実行時間から、改善が確認できたかを結論づけてください。</li>
</ol>
<pre><code class="language-sql">
-- ステップ1: 現状確認
EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id, order_date, amount
FROM orders
WHERE status = 'paid'
ORDER BY order_date DESC
LIMIT 100;

-- ステップ2: 仮説と対策（並び替えと条件に合わせた索引）
CREATE INDEX IF NOT EXISTS idx_orders_status_date_desc
ON orders(status, order_date DESC)
INCLUDE (amount);
ANALYZE orders;

-- ステップ3: 事後検証
EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id, order_date, amount
FROM orders
WHERE status = 'paid'
ORDER BY order_date DESC
LIMIT 100;
</code></pre>
<details>
  <summary>解答例を見る</summary>
  <pre><code class="language-sql">
-- 解答例
CREATE INDEX IF NOT EXISTS idx_orders_status_date_desc
ON orders(status, order_date DESC)
INCLUDE (amount);
ANALYZE orders;

EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id, order_date, amount
FROM orders
WHERE status = 'paid'
ORDER BY order_date DESC
LIMIT 100;

-- 観察ポイント:
-- Sortノードの有無
-- 実行時間とread/hitの変化
  </code></pre>
  <p>
  解説：ORDER BY と WHERE の両方に合う索引を用意すると、Sortコストを削減できる場合があります。Sortノード有無を必ず確認してください。
  </p>
  <p><strong>解答例</strong></p>
  <p>
  1. インデックス追加後は <code>Sort</code> ノードが消える（または負荷が低下する）結果になりました。<br>
  2. 理由は ORDER BY 方向とインデックス列順が一致し、並べ替え処理を省略しやすくなったためです。<br>
  3. 実行時間とBUFFERSの両方で改善が見られ、索引追加の効果を確認できました。
  </p>
</details>

<h3>ex-06.sql：統計情報を古い状態にして計画悪化を再現し、改善差を比較してください。</h3>
<p><strong>課題</strong>：ステップ1〜3を実行し、以下の問いに答えてください。</p>
<ol>
  <li>統計更新前後で <code>rows</code> 推定誤差はどの程度変化しましたか。</li>
  <li><code>Node Type</code> と実行時間はどう変化しましたか。改善/悪化を具体的に書いてください。</li>
  <li>この結果を、<span class="highlight">統計情報の更新タイミング</span>という言葉を使って説明してください。</li>
</ol>
<pre><code class="language-sql">
-- ステップ1: 現状確認
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE status = 'new' AND shipping_pref = 'tokyo';

-- ステップ2: 仮説と対策（分布を偏らせ、統計未更新状態を作る）
UPDATE orders
SET status = 'new', shipping_pref = 'tokyo'
WHERE order_id % 9 &lt; 7;

EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE status = 'new' AND shipping_pref = 'tokyo';

-- 統計更新で対策
ANALYZE orders;

-- ステップ3: 事後検証
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE status = 'new' AND shipping_pref = 'tokyo';
</code></pre>
<details>
  <summary>解答例を見る</summary>
  <pre><code class="language-sql">
-- 解答例
UPDATE orders
SET status = 'new', shipping_pref = 'tokyo'
WHERE order_id % 9 &lt; 7;

EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE status = 'new' AND shipping_pref = 'tokyo';

ANALYZE orders;

EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM orders WHERE status = 'new' AND shipping_pref = 'tokyo';

-- 観察ポイント:
-- rows推定誤差の縮小
-- Node Typeの変化
-- 実行時間とbuffersの改善
  </code></pre>
  <p>
  解説：統計が古い状態では不利な計画が選ばれることがあります。ANALYZE後に Node Type と BUFFERS の改善を比較してください。
  </p>
  <p><strong>解答例</strong></p>
  <p>
  1. 統計更新前は rows 推定誤差が大きく、実態と乖離した計画が選ばれていました。<br>
  2. <code>ANALYZE</code> 後は推定誤差が縮小し、Node Type と実行時間が改善しました。<br>
  3. したがって、統計情報の更新タイミングが遅いと性能劣化を招くため、更新後に再計測する運用が必要です。
  </p>
</details>

<div class="column">
  <div class="column-title">追加演習：自分の業務SQLを1本持ち込み、同じ手順で評価してみましょう</div>
  <p class="column-note">
    現在の計画、仮説、改善SQL、再測定結果を1セットで残してください。比較可能な記録があると再発防止に役立ちます。
  </p>
</div>

<details>
  <summary>追加演習の解答例</summary>
  <p>
    追加演習は「1本の業務SQLを、同じ条件で前後比較できる形にする」ことが正解です。
    まず現状計測を3回行って中央値を記録し、次に仮説に基づく変更を1つだけ適用して再計測します。
    変更を同時に複数入れると、どれが効いたか説明できなくなるため避けてください。
  </p>
  <pre><code class="language-sql">
-- 1) 現状計測（同じSQLを3回）
EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id, customer_id, amount
FROM orders
WHERE status = 'paid'
  AND order_date &gt;= current_date - 30
ORDER BY order_date DESC
LIMIT 200;

-- 2) 仮説: status + order_date の複合索引が有効
CREATE INDEX IF NOT EXISTS idx_orders_paid_recent
ON orders(status, order_date DESC)
INCLUDE (amount, customer_id);
ANALYZE orders;

-- 3) 再計測
EXPLAIN (ANALYZE, BUFFERS)
SELECT order_id, customer_id, amount
FROM orders
WHERE status = 'paid'
  AND order_date &gt;= current_date - 30
ORDER BY order_date DESC
LIMIT 200;
  </code></pre>
  <p>
    解答時は、<span class="highlight">Node Type</span>、<span class="highlight">actual rows</span>、
    <span class="highlight">BUFFERS read/hit</span>、<span class="highlight">実行時間中央値</span>の4点を前後比較して説明してください。
  </p>
</details>

<h3>定着確認（第8章）</h3>
<ul>
  <li>ドリルは <span class="masked">現状確認→対策→事後検証</span> の3段階で進めるべきである。</li>
  <li>比較結果は <span class="masked">計画・実行時間・BUFFERS</span> をセットで記録すべきである。</li>
  <li>改善判断は <span class="masked">再現可能な比較結果</span> を根拠に行うべきである。</li>
</ul>

<h2>EXハンズオン：実行計画演習</h2>
<p>
本記事の主軸は <code>orders/customers</code> ですが、講義で使うゲームDBでも同じ分析手順を適用できます。
以下は <code>from-teacher/10/create-x_db.sql</code> と <code>from-teacher/10/insert-x_db_01.sql</code> を前提にした、任意の補助ドリルです。
</p>
<p>
このEXハンズオンも「正しいSQLを書く」問題ではありません。用意されたSQLを実行し、
出力された実行計画（EXPLAINの結果）を読み解いて、<span class="highlight-strong">なぜその計画になったのかを考察する分析レポートを書く</span>練習です。
Node Type、rows/actual rows、BUFFERS、実行時間を根拠として説明してください。
</p>

<div class="column">
  <div class="column-title">ER図</div>
  <p class="column-note">
    参照先テーブルの関係を先に確認してから、JOIN計画と集計計画を読み解いてください。
  </p>
  <img src="images/LER-01.png" alt="create-x_db.sql のER図" />
</div>

<div class="column">
  <div class="column-title">準備コマンド</div>
  <pre><code class="language-bash">
# スキーマ再作成
npm run sql from-teacher/10/create-x_db.sql

# 初期データ投入（本ドリルの前提）
npm run sql from-teacher/10/insert-x_db_01.sql

# 必要なら検証用SQLファイルを開く
code sql/tmp_ep_xdb.sql
npm run sql sql/tmp_ep_xdb.sql
  </code></pre>
</div>

<h3>EXドリル01：ギルド所属JOINの計画を読む</h3>
<p>
目的は、<code>x_characters</code> と <code>x_guild_characters</code> のJOINで、
入力行数に応じてどのノードが選ばれるかを観測することです。
</p>
<p><strong>課題</strong>：SQLを実行し、以下の問いに答えてください。</p>
<ol>
  <li>JOINノードとして何が選ばれましたか（<code>Nested Loop</code> / <code>Hash Join</code> など）。</li>
  <li><code>rows</code> と <code>actual rows</code> の差から、推定精度は妥当でしたか。</li>
  <li>結果を、<span class="highlight">入力行数</span>という言葉を使って説明してください。</li>
</ol>
<pre><code class="language-sql">
EXPLAIN (ANALYZE, BUFFERS)
SELECT c.character_id, c.name, gc.guild_id
FROM x_characters c
JOIN x_guild_characters gc ON gc.character_id = c.character_id
WHERE c.deleted_at IS NULL;
</code></pre>
<details>
  <summary>解答例を見る</summary>
  <pre><code class="language-sql">
-- 期待する見方
-- 1) Node Type（Nested Loop / Hash Join など）
-- 2) rows と actual rows の差
-- 3) BUFFERS read/hit

EXPLAIN (ANALYZE, BUFFERS)
SELECT c.character_id, c.name, gc.guild_id
FROM x_characters c
JOIN x_guild_characters gc ON gc.character_id = c.character_id
WHERE c.deleted_at IS NULL;
  </code></pre>
  <p>
    行数が小さい初期状態では Nested Loop が選ばれやすく、件数増加時は Hash Join へ切り替わる可能性があります。
    切替の有無は統計情報と件数分布で変わるため、実測で確認してください。
  </p>
  <p><strong>解答例</strong></p>
  <p>
  1. 今回の実行では JOIN ノードとして <code>Nested Loop</code>（または <code>Hash Join</code>）が選ばれました。<br>
  2. <code>rows</code> と <code>actual rows</code> の差は小さく（または大きく）、推定精度は概ね妥当（または改善余地あり）と判断しました。<br>
  3. 理由は入力行数です。入力行数が少ない条件では逐次探索が有利になりやすく、増えるとハッシュ結合が有利になります。
  </p>
</details>

<h3>EXドリル02：送金履歴の集計計画を読む</h3>
<p>
目的は、<code>x_gold_transfers</code> の集計で HashAggregate / GroupAggregate の違いを観測することです。
</p>
<p><strong>課題</strong>：SQLを実行し、以下の問いに答えてください。</p>
<ol>
  <li>集計ノードとして何が選ばれましたか（<code>HashAggregate</code> / <code>GroupAggregate</code>）。</li>
  <li><code>Sort</code> ノードの有無と、その影響を実行時間から説明してください。</li>
  <li>結果を、<span class="highlight">グループ数</span>という言葉を使って説明してください。</li>
</ol>
<pre><code class="language-sql">
EXPLAIN (ANALYZE, BUFFERS)
SELECT to_character_id, COUNT(*) AS transfer_count, SUM(amount) AS total_amount
FROM x_gold_transfers
GROUP BY to_character_id
ORDER BY transfer_count DESC;
</code></pre>
<details>
  <summary>解答例を見る</summary>
  <pre><code class="language-sql">
EXPLAIN (ANALYZE, BUFFERS)
SELECT to_character_id, COUNT(*) AS transfer_count, SUM(amount) AS total_amount
FROM x_gold_transfers
GROUP BY to_character_id
ORDER BY transfer_count DESC;

-- 観察ポイント
-- ・Groupノードの種類（HashAggregate / GroupAggregate）
-- ・Sortノードの有無
-- ・rows推定誤差と実行時間
  </code></pre>
  <p>
    グループ数が少ない場合はHashAggregateが有利になりやすいですが、
    メモリ設定や入力順序によってはGroupAggregateが選ばれることがあります。
  </p>
  <p><strong>解答例</strong></p>
  <p>
  1. 今回は集計ノードとして <code>HashAggregate</code>（または <code>GroupAggregate</code>）が選ばれました。<br>
  2. <code>Sort</code> ノードは存在した（または存在しなかった）ため、実行時間に追加コストが発生した（または抑えられた）と判断しました。<br>
  3. 理由はグループ数です。グループ数が少ない場合はハッシュ集計が有利になりやすく、条件次第で並び替え主体の集計が選ばれることもあります。
  </p>
</details>

<h2>9. まとめ</h2>
<ul>
  <li>Node・rows誤差・buffers をセットで確認する。</li>
  <li>選択性と列順を基準にインデックスを比較する。</li>
  <li>統計が古い場合は ANALYZE を優先して実行する。</li>
  <li>キャッシュ状態や同時実行の影響を切り分ける。</li>
  <li>仮説→計画比較→再測定の順で改善する。</li>
</ul>

<div class="column">
  <div class="column-title">次のステップ</div>
  <p class="column-note">
    次回は <code>pg_stat_statements</code> と <code>auto_explain</code> を併用し、
    「本番に近い継続観測」と「再現性あるチューニング手順」を設計します。
  </p>
</div>

<p class="footer-text">制作時間：22時間</p>
<footer class="footer">
  <a class="footer-link" href="https://github.com/Tsubasa213" target="_blank" rel="noopener noreferrer">GitHub</a>
  <p class="footer-text">© copyright 2026 Tsubasa213/つばさ all right resolved.</p>
</footer>

</body>
<script src="main.js"></script>
<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.9.0/build/highlight.min.js"></script>
<script>hljs.highlightAll();</script>
<iframe
  src="https://docsbot.ai/iframe/4dWqauk5JhWuOOyVaU35/LcmBqB48fmMf6m6LgGL1"
  frameborder="0"
  scrolling="no"
  class="docsbot-frame">
</iframe>
</html>
